{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivasurasani/research_paper_recommendation_system/blob/main/Rec_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing pandas and extracting the desired dataset"
      ],
      "metadata": {
        "id": "F_yBa5maArFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(\"DM_dataset.csv\")\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV: {e}\")\n",
        "    print(\"Trying to read with error_bad_lines=False and quoting=3\")\n",
        "    df = pd.read_csv(\"DM_dataset.csv\", on_bad_lines='skip', quoting=3)\n",
        "\n",
        "    if df.isnull().values.any():\n",
        "        print(\"Warning: Some rows are skipped due to errors. Please check the data for inconsistencies.\")"
      ],
      "metadata": {
        "id": "mgnaG3FVZW_q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing sentence transformers and torch"
      ],
      "metadata": {
        "id": "V_CBVXkEAw-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q sentence-transformers\n",
        "%pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_56ecDo_Wkf",
        "outputId": "16096e2a-f93f-4d2e-9385-bdb62964a885"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the models in a Models directory"
      ],
      "metadata": {
        "id": "0MUqVCPNA2mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "directory = \"Models/\"\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ],
      "metadata": {
        "id": "q-TE1np9bwCe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "KG9mj6rkA7L7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = [\"terms\",\"abstracts\"], inplace = True)\n",
        "df.drop_duplicates(inplace= True)\n",
        "df.reset_index(drop= True,inplace = True)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "WtaFslfx_zJ0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creading sentence embeddings"
      ],
      "metadata": {
        "id": "qdf4gkQBA-Qd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxVISosOYyUp",
        "outputId": "4cf0b0aa-6531-4bfc-d481-c1cd766fab24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: Multi-Level Attention Pooling for Graph Neural Networks: Unifying Graph Representations with Multiple Localities\n",
            "Embedding length: 384\n",
            "Sentence: Decision Forests vs. Deep Networks: Conceptual Similarities and Empirical Differences at Small Sample Sizes\n",
            "Embedding length: 384\n",
            "Sentence: Power up! Robust Graph Convolutional Network via Graph Powering\n",
            "Embedding length: 384\n",
            "Sentence: Releasing Graph Neural Networks with Differential Privacy Guarantees\n",
            "Embedding length: 384\n",
            "Sentence: Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern Classification\n",
            "Embedding length: 384\n",
            "Sentence: Lifelong Graph Learning\n",
            "Embedding length: 384\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "sentences = df['titles']\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "result_limit = 0\n",
        "\n",
        "for sentence, embedding in zip(sentences, embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding length:\", len(embedding))\n",
        "    if result_limit >= 5:\n",
        "        break\n",
        "    result_limit = result_limit + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the models using pickle"
      ],
      "metadata": {
        "id": "B_D9NAtxBE5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('Models/embeddings.pkl', 'wb') as emb:\n",
        "    pickle.dump(embeddings, emb)\n",
        "\n",
        "with open('Models/rec_model.pkl', 'wb') as rec_mod:\n",
        "    pickle.dump(model, rec_mod)\n",
        "\n",
        "with open('Models/sentences.pkl', 'wb') as sent:\n",
        "    pickle.dump(sentences, sent)\n",
        "\n",
        "\n",
        "sentences_embeddings = pickle.load(open('Models/embeddings.pkl','rb'))\n",
        "all_sentences = pickle.load(open('Models/sentences.pkl','rb'))\n",
        "rec_model = pickle.load(open('Models/rec_model.pkl','rb'))\n"
      ],
      "metadata": {
        "id": "HCzkAZ7c_3uG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommending top five research papers"
      ],
      "metadata": {
        "id": "cgTpJc-LBH2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def recommendation_definition(input_paper):\n",
        "    scores_similarities_cosine = util.cos_sim(sentences_embeddings, rec_model.encode(input_paper))\n",
        "\n",
        "    top_five_recommendations = torch.topk(scores_similarities_cosine, dim=0, k=5, sorted=True)\n",
        "\n",
        "    list_of_papers = []\n",
        "    for r in top_five_recommendations.indices:\n",
        "        list_of_papers.append(all_sentences[r.item()])\n",
        "    return list_of_papers\n",
        "\n",
        "input_paper = input(\"Enter the title for recommendations\")\n",
        "recommend_papers = recommendation_definition(input_paper)\n",
        "for paper in recommend_papers:\n",
        "    print(\"\\n\")\n",
        "    print(paper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgY4n52g_7-w",
        "outputId": "ef4394ed-f3da-4f0e-8b06-ec11ddb8a968"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the title for recommendationsMachine learning applications\n",
            "\n",
            "\n",
            "Reinforcement Learning Applications\n",
            "\n",
            "\n",
            "Techniques for Automated Machine Learning\n",
            "\n",
            "\n",
            "Applications of Deep Neural Networks\n",
            "\n",
            "\n",
            "Applications of Machine Learning in Document Digitisation\n",
            "\n",
            "\n",
            "Machine learning with limited data\n"
          ]
        }
      ]
    }
  ]
}